# Character Recognition using Convolutional Autoencoder

This project implements a Convolutional Autoencoder (ConvAE) for character recognition/reconstruction using the MNIST dataset. The model learns to compress images into a low-dimensional latent space and then reconstruct them.

## Project Structure

- `ConAE.ipynb`: The main Jupyter Notebook containing the data loading, model definition, training loop, and visualization code.
- `extract_images.py`: A script to extract images generated by the notebook.
- `output_*.png`: Extracted images visualizing the data, training progress, and latent space.

## Model Architecture

The Convolutional Autoencoder consists of:

- **Encoder**: Compresses the 28x28 input image into a latent vector (embedding_dim=3).
  - Conv2d layers with ReLU activations and MaxPool2d.
  - Flatten and Linear layer to the embedding dimension.
- **Decoder**: Reconstructs the image from the latent vector.
  - Linear layer and Unflatten.
  - ConvTranspose2d layers with ReLU activations.
  - Final Conv2d layer with Sigmoid activation to output pixel values between 0 and 1.

## Training

The model is trained using:
- **Loss Function**: BCELoss (Binary Cross Entropy Loss) + L2 Regularization.
- **Optimizer**: Adam with learning rate 0.001.

## Visualizations

Below are the images produced during the execution of the notebook.

### Data Visualization
Initial data exploration and sample images.
![Sample](./output_1.png)

### Training Loss
Plot of the training loss over epochs.
![Loss](./output_2.png)

### Latent Space Visualization
Visualizing the learned features in the latent space.
![Latent Space](./output_3.png)
![Latent Space](./output_5.png)
![Output 6](./output_6.png)
![Output 7](./output_7.png)

### Reconstructions and Training Progress
Various outputs showing the model's performance and training progression.

![Output 8](./output_8.png)
![Output 9](./output_9.png)
![Output 10](./output_10.png)
![Output 11](./output_11.png)
![Output 12](./output_12.png)
![Output 13](./output_13.png)
![Output 14](./output_14.png)
![Output 15](./output_15.png)
![Output 16](./output_16.png)
![Output 17](./output_17.png)
![Output 18](./output_18.png)
![Output 19](./output_19.png)
![Output 20](./output_20.png)
![Output 21](./output_21.png)
![Output 22](./output_22.png)
![Output 23](./output_23.png)
![Output 24](./output_24.png)
![Output 25](./output_25.png)
![Output 26](./output_26.png)
![Output 27](./output_27.png)
